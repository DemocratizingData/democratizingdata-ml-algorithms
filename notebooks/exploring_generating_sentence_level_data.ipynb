{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Document-level Data and Labels Into Sentence-Level Data and Labels\n",
    "\n",
    "This notebook explores converting the document-level data and labels into\n",
    "sentence-level data and labels for training Masked Language Models, like Kaggle\n",
    "model 1, and Named Entity Recognition models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from itertools import count, islice\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import spacy\n",
    "from unidecode import unidecode\n",
    "\n",
    "import src.models.regex_model as rm\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pub_title</th>\n",
       "      <th>dataset_title</th>\n",
       "      <th>dataset_label</th>\n",
       "      <th>cleaned_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0fa7568-7d8e-4db9-870f-f9c6f668c17b</td>\n",
       "      <td>The Impact of Dual Enrollment on College Degre...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>Educational Attainment of High School Dropouts...</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>National Education Longitudinal Study</td>\n",
       "      <td>national education longitudinal study</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id  \\\n",
       "0  d0fa7568-7d8e-4db9-870f-f9c6f668c17b   \n",
       "1  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "\n",
       "                                           pub_title  \\\n",
       "0  The Impact of Dual Enrollment on College Degre...   \n",
       "1  Educational Attainment of High School Dropouts...   \n",
       "\n",
       "                           dataset_title  \\\n",
       "0  National Education Longitudinal Study   \n",
       "1  National Education Longitudinal Study   \n",
       "\n",
       "                           dataset_label  \\\n",
       "0  National Education Longitudinal Study   \n",
       "1  National Education Longitudinal Study   \n",
       "\n",
       "                           cleaned_label  \n",
       "0  national education longitudinal study  \n",
       "1  national education longitudinal study  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_labels = pd.read_csv(\"../data/kaggle/train.csv\")\n",
    "kaggle_labels.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains only a single label for each line, so we need to aggregate them \n",
    "by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d0fa7568-7d8e-4db9-870f-f9c6f668c17b</td>\n",
       "      <td>National Education Longitudinal Study|Educatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f26f645-3dec-485d-b68d-f013c9e05e60</td>\n",
       "      <td>National Education Longitudinal Study|Educatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  \\\n",
       "0  d0fa7568-7d8e-4db9-870f-f9c6f668c17b   \n",
       "1  2f26f645-3dec-485d-b68d-f013c9e05e60   \n",
       "\n",
       "                                               label  \n",
       "0  National Education Longitudinal Study|Educatio...  \n",
       "1  National Education Longitudinal Study|Educatio...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_labels = pd.DataFrame({\"id\": kaggle_labels[\"Id\"].unique()})\n",
    "\n",
    "def aggregate_clean_label(row: pd.DataFrame):\n",
    "    labels = list(map(lambda x: x.strip(), row[\"dataset_label\"].unique()))\n",
    "    return \"|\".join(labels)\n",
    "\n",
    "unique_labels = kaggle_labels.groupby(\"Id\").apply(aggregate_clean_label)\n",
    "aggregated_labels[\"label\"] = aggregated_labels[\"id\"].apply(lambda x: unique_labels[x])\n",
    "aggregated_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This study used data from\n",
      "National Education Longitudinal Study|Education Longitudinal Study\n"
     ]
    }
   ],
   "source": [
    "document_id = aggregated_labels.id.values[0]\n",
    "\n",
    "with open(\"../data/kaggle/train/\" + document_id + \".json\") as f:\n",
    "    document = json.load(f)\n",
    "\n",
    "text = unidecode(\" \".join(list(map(\n",
    "    lambda x: x[\"text\"].strip().replace(\"\\n\", \" \"), \n",
    "    document\n",
    "))))\n",
    "\n",
    "label = aggregated_labels[aggregated_labels.id == document_id].label.values[0]\n",
    "\n",
    "print(text[:25])\n",
    "print(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce a sentence level dataset we will spaCy to parse the document and\n",
    "split it into sentences. We will then assign tags and store in a format similar\n",
    "to [CoNLL-2003](https://www.clips.uantwerpen.be/conll2003/ner/), which is a popular dataset for NER based models. The CoNLL-2003\n",
    "data looks like this:\n",
    "\n",
    "```\n",
    "   U.N.         NNP  I-NP  I-ORG \n",
    "   official     NN   I-NP  O \n",
    "   Ekeus        NNP  I-NP  I-PER \n",
    "   heads        VBZ  I-VP  O \n",
    "   for          IN   I-PP  O \n",
    "   Baghdad      NNP  I-NP  I-LOC \n",
    "   .            .    O     O \n",
    "```\n",
    "\n",
    "The first column contains the tokens, the second column contains the\n",
    "part-of-speech tagging, the third column contains the syntactic chunk tagging,\n",
    "and the fourth column contains the named entity tagging.\n",
    "\n",
    "We will use the same format, but we will only use the first two columns and add\n",
    "a third column indicating the label for each token using the [IOB\n",
    "format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)).\n",
    "\n",
    "\n",
    "Our tags will be `I-DAT`, `O`, and `B-DAT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanhausen/anaconda3/envs/democratizing-data-ml-algorithms/lib/python3.10/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "parsed_document = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out the text and tokens for a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:\n",
      " This study used data from the National Education Longitudinal Study (NELS:88) to examine the effects of dual enrollment programs for high school students on college degree attainment.\n",
      "This\tDT\n",
      "study\tNN\n",
      "used\tVBD\n",
      "data\tNNS\n",
      "from\tIN\n",
      "the\tDT\n",
      "National\tNNP\n",
      "Education\tNNP\n",
      "Longitudinal\tNNP\n",
      "Study\tNNP\n",
      "(\t-LRB-\n",
      "NELS:88\tNNP\n",
      ")\t-RRB-\n",
      "to\tTO\n",
      "examine\tVB\n",
      "the\tDT\n",
      "effects\tNNS\n",
      "of\tIN\n",
      "dual\tJJ\n",
      "enrollment\tNN\n"
     ]
    }
   ],
   "source": [
    "for sentence in islice(parsed_document.sents, 1):\n",
    "    print(\"Sentence:\\n\", sentence)\n",
    "    for token in islice(sentence, 20):\n",
    "        print(\"\\t\".join([token.text, token.tag_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add the labels we need to see if any of the labels are in the sentence first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thrown in a bad label to test for false positives\n",
    "labels = label.split(\"|\") + [\"Banana Pancakes\"]\n",
    "rm.RegexModel.regexify_keyword(labels[0])\n",
    "regex_labels = list(map(\n",
    "    re.compile,\n",
    "    map(rm.RegexModel.regexify_keyword, labels)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(sentence)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanhausen/anaconda3/envs/democratizing-data-ml-algorithms/lib/python3.10/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "def detect_labels(labels:List[re.Pattern], sentence:str) -> List[List[str]]:\n",
    "    return list(map(\n",
    "        lambda match: match.captures(), # It's possible to have more than one match\n",
    "        filter(\n",
    "            bool,\n",
    "            map(\n",
    "                lambda rl: rl.search(sentence),\n",
    "                labels\n",
    "            )\n",
    "        )\n",
    "    ))\n",
    "\n",
    "def tag_sentence(regex_labels:List[re.Pattern], sentence:spacy.tokens.span.Span):\n",
    "    match_lists = sorted(\n",
    "        detect_labels(regex_labels, sentence.text), \n",
    "        key=lambda x: max(map(len, x)), \n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    tokens = [token.text for token in sentence]\n",
    "    tags = [token.tag_ for token in sentence]\n",
    "    ner_tags = [\"O\"] * len(sentence) # assume no match\n",
    "\n",
    "    for matches in match_lists:\n",
    "        for match in matches:\n",
    "            label_tokens = nlp(match)\n",
    "            start_idx = tokens.index(label_tokens[0].text)\n",
    "            idxs = list(range(start_idx, start_idx + len(label_tokens)))\n",
    "\n",
    "\n",
    "            first_tag = ner_tags[start_idx]\n",
    "            prev_tag = ner_tags[start_idx - 1] if start_idx > 0 else \"O\"\n",
    "            # If there are any tokens that are already marked then this match\n",
    "            # could be a subset of another match\n",
    "            if not any(map(lambda x: x!=\"O\", ner_tags[start_idx: start_idx + len(label_tokens)])):\n",
    "                if prev_tag==\"O\":\n",
    "                    ner_tags[start_idx] = \"I-DAT\"\n",
    "                else:\n",
    "                    ner_tags[start_idx] = \"B-DAT\"\n",
    "\n",
    "                for idx in idxs[1:]:\n",
    "                    ner_tags[idx] = \"I-DAT\"\n",
    "\n",
    "    return tokens, tags, ner_tags\n",
    "    \n",
    "for sentence in islice(parsed_document.sents, 1):\n",
    "    tokens, tags, ner_tags = tag_sentence(regex_labels, sentence)\n",
    "\n",
    "# TODO: how best to store the data?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "democratizing-data-ml-algorithms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b291ab9446582050e02bff38bdb2cc08a6891ecc485df1df216546589a982e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
