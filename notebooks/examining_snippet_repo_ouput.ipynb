{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook looks at the output from the snippet repository\n",
    "and how to use it to train NER, classification, and mlm models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "from spacy import displacy\n",
    "import src.data.snippet_repository as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Enitiy Recognition Models (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_repo = sr.SnippetRepository(sr.SnippetRepositoryMode.NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data = ner_repo.get_training_data(batch_size=10)\n",
    "detected = False\n",
    "while not detected:\n",
    "    ner_df = next(ner_data)\n",
    "    detected = any(ner_df['ner_tags'].apply(lambda ner_tags: any(map(lambda t: t!=\"O\", ner_tags))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Elementary and Secondary Mathematics and Science Education Two States ' Performance on TIMSS : 2007 Massachusetts and Minnesota participated in a special benchmarking study included in the \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Dataset</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trends in International Mathematics and Science Study \n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Dataset</span>\n",
       "</mark>\n",
       "( TIMSS ) 2007 , along with three Canadian provinces , the city of Dubai , and one region of Spain .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = ner_df.iloc[9].text\n",
    "ner_tags = ner_df.iloc[9].ner_tags\n",
    "sr.visualize_ner_tags(text, ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model here\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ef06adfa784f20a1423e1ec7ddfc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"dslim/bert-base-NER\",\n",
       "  \"_num_labels\": 9,\n",
       "  \"architectures\": [\n",
       "    \"BertForTokenClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-MISC\",\n",
       "    \"2\": \"I-MISC\",\n",
       "    \"3\": \"B-PER\",\n",
       "    \"4\": \"I-PER\",\n",
       "    \"5\": \"B-ORG\",\n",
       "    \"6\": \"I-ORG\",\n",
       "    \"7\": \"B-LOC\",\n",
       "    \"8\": \"I-LOC\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"B-LOC\": 7,\n",
       "    \"B-MISC\": 1,\n",
       "    \"B-ORG\": 5,\n",
       "    \"B-PER\": 3,\n",
       "    \"I-LOC\": 8,\n",
       "    \"I-MISC\": 2,\n",
       "    \"I-ORG\": 6,\n",
       "    \"I-PER\": 4,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 28996\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoConfig.from_pretrained(\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"dslim/bert-base-NER\", \n",
    "    output_attentions=True,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1188, 1110, 6876, 3087, 1105, 1122, 1110, 5372,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = tokenizer(\n",
    "    \"This is sample text and it is grand\".split(), \n",
    "    is_split_into_words=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = model(**features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 768]), torch.Size([1, 12, 10, 10]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.hidden_states[0].shape, outs.attentions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0984e-01, 1.7902e-02, 4.4900e-03, 7.2620e-03, 8.8475e-03, 5.9365e-03,\n",
       "         2.4017e-02, 5.7133e-03, 1.8693e-02, 3.9729e-01],\n",
       "        [1.5214e-01, 8.2471e-02, 1.0092e-01, 2.0781e-01, 1.0100e-01, 6.3148e-03,\n",
       "         8.7182e-02, 9.8551e-02, 7.8215e-02, 8.5383e-02],\n",
       "        [5.3224e-02, 5.3401e-02, 2.6654e-01, 2.0507e-01, 6.4948e-02, 2.5070e-02,\n",
       "         6.6980e-02, 2.0637e-01, 2.1779e-02, 3.6618e-02],\n",
       "        [2.1338e-01, 1.1654e-01, 1.0632e-01, 1.4516e-01, 1.0935e-01, 1.4510e-02,\n",
       "         8.8916e-02, 1.2407e-01, 6.2667e-02, 1.9075e-02],\n",
       "        [4.0572e-02, 9.8657e-02, 6.6175e-02, 2.5272e-01, 1.2026e-01, 5.1738e-02,\n",
       "         1.1349e-01, 6.9439e-02, 1.6019e-01, 2.6759e-02],\n",
       "        [1.1624e-01, 1.3273e-01, 6.0380e-02, 1.8915e-01, 8.1651e-02, 6.3257e-02,\n",
       "         1.1841e-01, 5.4545e-02, 9.2658e-02, 9.0974e-02],\n",
       "        [8.4839e-02, 1.2499e-01, 9.5169e-02, 2.3637e-01, 7.8517e-02, 3.1685e-02,\n",
       "         1.2090e-01, 7.2664e-02, 5.8738e-02, 9.6132e-02],\n",
       "        [4.1770e-02, 5.5790e-02, 2.8593e-01, 1.9694e-01, 5.3139e-02, 3.6806e-02,\n",
       "         6.0937e-02, 2.0107e-01, 2.2303e-02, 4.5314e-02],\n",
       "        [6.1076e-02, 7.5842e-02, 1.2130e-01, 2.8022e-01, 1.4744e-01, 1.6505e-02,\n",
       "         8.6544e-02, 1.2360e-01, 3.1095e-02, 5.6375e-02],\n",
       "        [1.0936e-01, 1.4771e-02, 8.1692e-03, 2.4893e-03, 7.4717e-03, 5.7864e-05,\n",
       "         1.7486e-03, 3.3153e-03, 4.1983e-03, 8.4842e-01]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.attentions[0][0, 0,...]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('democratizingdata-ml-algo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3e03aa19f4cee1cca181f326aea7726af1ea307b5fcbfd54a41f945b089b370"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
